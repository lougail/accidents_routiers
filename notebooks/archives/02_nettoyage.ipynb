{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2a3abf",
   "metadata": {},
   "source": [
    "# Nettoyage & ETL - Accidents routiers\n",
    "\n",
    "## Objectif\n",
    "Fusionner les 3 tables en un dataset propre, avec :\n",
    "- Une ligne par accident\n",
    "- Une variable cible : accident mortel (oui/non)\n",
    "- Des features exploitables pour le ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d082da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caract: (54402, 15), Lieux: (70248, 18), Usagers: (125187, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données 2024\n",
    "caract = pd.read_csv('../données/2024/caract-2024.csv', sep=';')\n",
    "lieux = pd.read_csv('../données/2024/lieux-2024.csv', sep=';')\n",
    "usagers = pd.read_csv('../données/2024/usagers-2024.csv', sep=';')\n",
    "\n",
    "print(f\"Caract: {caract.shape}, Lieux: {lieux.shape}, Usagers: {usagers.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d7133",
   "metadata": {},
   "source": [
    "## Stratégie de fusion\n",
    "\n",
    "### Features (ce qu'on connaît AVANT l'accident)\n",
    "- **CARACT** : conditions temporelles, météo, luminosité, localisation\n",
    "- **LIEUX** : caractéristiques de la route\n",
    "\n",
    "### Target (ce qu'on prédit)\n",
    "- Accident mortel (oui/non) : agrégé depuis USAGERS\n",
    "\n",
    "### Colonnes exclues (data leakage)\n",
    "- `col` (type de collision) : résultat de l'accident\n",
    "- **VEHICULES** : on ne sait pas quels véhicules seront impliqués\n",
    "- **USAGERS** (sauf grav) : on ne sait pas qui sera impliqué\n",
    "\n",
    "### Problèmes à traiter\n",
    "1. Coordonnées GPS parfois invalides\n",
    "2. Valeurs manquantes codées autrement que NaN\n",
    "3. Date/heure éclatée sur plusieurs colonnes\n",
    "4. Plusieurs lieux par accident"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h4w1glf75i4",
   "metadata": {},
   "source": [
    "## Gestion des lieux multiples\n",
    "\n",
    "Certains accidents ont plusieurs lieux (intersections). Il faut décider comment n'en garder qu'un."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee47e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple accident 202400000002 :\n",
      "        Num_Acc  catr                    voie  vma  surf\n",
      "1  202400000002     4  HOTEL DIEU (RUE DE L')   30     9\n",
      "2  202400000002     4           POTERNE (RUE)   30     9\n"
     ]
    }
   ],
   "source": [
    "# Accidents avec 2 lieux\n",
    "accidents_2_lieux = lieux.groupby('Num_Acc').filter(lambda x: len(x) == 2)\n",
    "\n",
    "# Prendre un exemple\n",
    "exemple_acc = accidents_2_lieux['Num_Acc'].iloc[0]\n",
    "print(f\"Exemple accident {exemple_acc} :\")\n",
    "print(lieux[lieux['Num_Acc'] == exemple_acc][['Num_Acc', 'catr', 'voie', 'vma', 'surf']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16544249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accidents multi-lieux avec catr et vma identiques : 10934 / 15645\n",
      "Soit 69.9%\n"
     ]
    }
   ],
   "source": [
    "# Pour les accidents à 2 lieux, est-ce que vma et catr sont identiques ?\n",
    "accidents_multi = lieux.groupby('Num_Acc').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Comparer les valeurs par accident\n",
    "def sont_identiques(group):\n",
    "    return group['vma'].nunique() == 1 and group['catr'].nunique() == 1\n",
    "\n",
    "resultats = accidents_multi.groupby('Num_Acc').apply(sont_identiques)\n",
    "print(f\"Accidents multi-lieux avec catr et vma identiques : {resultats.sum()} / {len(resultats)}\")\n",
    "print(f\"Soit {resultats.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7zgwcgnyeee",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "- 70% des accidents multi-lieux ont les mêmes `catr` et `vma`\n",
    "- 30% ont des caractéristiques différentes entre les lieux\n",
    "\n",
    "**Décision** : garder le premier lieu de chaque accident.\n",
    "- Simple et reproductible\n",
    "- Pour 70% des cas, ça ne change rien\n",
    "- Pour 30%, c'est un choix arbitraire mais acceptable\n",
    "\n",
    "Alternative possible : garder le lieu avec la `vma` la plus élevée (route principale). Mais ça complique sans garantie d'amélioration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335c2165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant : 70248 lignes\n",
      "Après : 54402 lignes\n",
      "Vérification : 54402 accidents uniques\n"
     ]
    }
   ],
   "source": [
    "# Garder un seul lieu par accident (le premier)\n",
    "lieux_unique = lieux.drop_duplicates(subset='Num_Acc')\n",
    "print(f\"Avant : {len(lieux)} lignes\")\n",
    "print(f\"Après : {len(lieux_unique)} lignes\")\n",
    "print(f\"Vérification : {lieux_unique['Num_Acc'].nunique()} accidents uniques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0l01spuak6si",
   "metadata": {},
   "source": [
    "## Création de la variable cible\n",
    "\n",
    "On agrège les usagers par accident : si au moins un usager a `grav == 2` (tué), l'accident est mortel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591ef43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortel\n",
      "0    51176\n",
      "1     3226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportion mortels : 5.9%\n"
     ]
    }
   ],
   "source": [
    "# Créer la target : accident mortel (oui/non)\n",
    "target = usagers.groupby('Num_Acc')['grav'].apply(lambda x: (x == 2).any())\n",
    "target = target.astype(int)  # Convertir True/False en 1/0\n",
    "target.name = 'mortel'\n",
    "\n",
    "print(target.value_counts())\n",
    "print(f\"\\nProportion mortels : {target.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bolriyro42",
   "metadata": {},
   "source": [
    "## Fusion des tables\n",
    "\n",
    "On fusionne :\n",
    "- `caract` (circonstances)\n",
    "- `lieux_unique` (1 lieu par accident)\n",
    "- `target_df` (mortel oui/non)\n",
    "\n",
    "Clé de jointure : `Num_Acc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47f30b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final : (54402, 33)\n",
      "Accidents mortels : 3226\n"
     ]
    }
   ],
   "source": [
    "# Convertir target en DataFrame\n",
    "target_df = target.reset_index()\n",
    "target_df.columns = ['Num_Acc', 'mortel']\n",
    "\n",
    "# Fusionner tout\n",
    "df = caract.merge(lieux_unique, on='Num_Acc').merge(target_df, on='Num_Acc')\n",
    "\n",
    "print(f\"Dataset final : {df.shape}\")\n",
    "print(f\"Accidents mortels : {df['mortel'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xrr5s3ai23",
   "metadata": {},
   "source": [
    "## Nettoyage\n",
    "\n",
    "### Suppression des colonnes data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be141fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer la colonne col (data leakage)\n",
    "df = df.drop(columns=['col'])\n",
    "print(f\"Colonnes restantes : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea965fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_Acc        0\n",
      "jour           0\n",
      "mois           0\n",
      "an             0\n",
      "hrmn           0\n",
      "lum            0\n",
      "dep            0\n",
      "com            0\n",
      "agg            0\n",
      "int            0\n",
      "atm            0\n",
      "adr         2310\n",
      "lat            0\n",
      "long           0\n",
      "catr           0\n",
      "voie        7293\n",
      "v1             0\n",
      "v2         48760\n",
      "circ           0\n",
      "nbv            0\n",
      "vosp           0\n",
      "prof           0\n",
      "pr             0\n",
      "pr1            0\n",
      "plan           0\n",
      "lartpc     54374\n",
      "larrout        0\n",
      "surf           0\n",
      "infra          0\n",
      "situ           0\n",
      "vma            0\n",
      "mortel         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explorer les valeurs manquantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rce7a3iz2ig",
   "metadata": {},
   "source": [
    "### Analyse des valeurs manquantes\n",
    "\n",
    "Deux types de valeurs manquantes :\n",
    "1. **NaN classiques** : `adr`, `voie`, `v2` (colonnes textuelles)\n",
    "2. **-1 cachés** : dans les colonnes numériques (convention de la base BAAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa46cbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 11437 valeurs à -1\n",
      "circ: 3524 valeurs à -1\n",
      "vosp: 1280 valeurs à -1\n",
      "prof: 11 valeurs à -1\n",
      "plan: 8 valeurs à -1\n",
      "surf: 6 valeurs à -1\n",
      "infra: 568 valeurs à -1\n",
      "situ: 5 valeurs à -1\n",
      "vma: 1567 valeurs à -1\n"
     ]
    }
   ],
   "source": [
    "# Chercher les -1 dans les colonnes numériques\n",
    "colonnes_num = df.select_dtypes(include=[np.number]).columns\n",
    "for col in colonnes_num:\n",
    "    nb_moins1 = (df[col] == -1).sum()\n",
    "    if nb_moins1 > 0:\n",
    "        print(f\"{col}: {nb_moins1} valeurs à -1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v9825t71chp",
   "metadata": {},
   "source": [
    "### Workflow de nettoyage\n",
    "\n",
    "1. **Supprimer colonnes inutiles** : `adr`, `voie`, `v1`, `v2`, `pr`, `pr1`, `Num_Acc`, `com`\n",
    "   - Texte brut non exploitable par le ML\n",
    "   - On garde `lat`/`long` et `dep` pour la localisation\n",
    "\n",
    "2. **Corriger les GPS** : format français (virgule → point) + filtrer métropole\n",
    "\n",
    "3. **Garder -1 pour les catégorielles** : le modèle peut apprendre que \"inconnu\" a un pattern\n",
    "\n",
    "4. **Imputer `vma`** si -1 : basé sur `catr` + `agg` (à faire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1ca394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes restantes : 24\n",
      "['jour', 'mois', 'an', 'hrmn', 'lum', 'dep', 'agg', 'int', 'atm', 'lat', 'long', 'catr', 'circ', 'nbv', 'vosp', 'prof', 'plan', 'lartpc', 'larrout', 'surf', 'infra', 'situ', 'vma', 'mortel']\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à supprimer\n",
    "cols_a_supprimer = ['adr', 'voie', 'v1', 'v2', 'pr', 'pr1', 'Num_Acc', 'com']\n",
    "\n",
    "df = df.drop(columns=cols_a_supprimer)\n",
    "print(f\"Colonnes restantes : {df.shape[1]}\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cqgqceaukme",
   "metadata": {},
   "source": [
    "### Suppression des colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "142afd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat - min: -22.433239, max: 51.07874\n",
      "Long - min: -178.094387, max: 167.863219\n",
      "\n",
      "GPS invalides : 3347 (6.2%)\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les coordonnées GPS\n",
    "# Convertir en float (format français : virgule → point)\n",
    "df['lat'] = df['lat'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['long'] = df['long'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "print(f\"Lat - min: {df['lat'].min()}, max: {df['lat'].max()}\")\n",
    "print(f\"Long - min: {df['long'].min()}, max: {df['long'].max()}\")\n",
    "\n",
    "# Compter les valeurs hors France ou à 0\n",
    "gps_invalides = (\n",
    "    (df['lat'] == 0) |\n",
    "    (df['long'] == 0) |\n",
    "    (df['lat'] < 41) | (df['lat'] > 52) |\n",
    "    (df['long'] < -6) | (df['long'] > 10)\n",
    ")\n",
    "print(f\"\\nGPS invalides : {gps_invalides.sum()} ({gps_invalides.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7sbwteb65x",
   "metadata": {},
   "source": [
    "### Nettoyage des coordonnées GPS\n",
    "\n",
    "Les coordonnées sont en format français (virgule décimale) et stockées comme texte.\n",
    "Il faut les convertir en float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc91b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type lat : float64\n",
      "Type long : float64\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le type actuel\n",
    "print(f\"Type lat : {df['lat'].dtype}\")\n",
    "print(f\"Type long : {df['long'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80010940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type lat : float64\n",
      "Lat - min: -22.43, max: 51.08\n",
      "Long - min: -178.09, max: 167.86\n"
     ]
    }
   ],
   "source": [
    "# Convertir lat/long en nombres (idempotent si déjà float)\n",
    "df['lat'] = df['lat'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['long'] = df['long'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "print(f\"Type lat : {df['lat'].dtype}\")\n",
    "print(f\"Lat - min: {df['lat'].min():.2f}, max: {df['lat'].max():.2f}\")\n",
    "print(f\"Long - min: {df['long'].min():.2f}, max: {df['long'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ily1izlj30f",
   "metadata": {},
   "source": [
    "### Filtrage France métropolitaine\n",
    "\n",
    "Les données incluent les DOM-TOM (La Réunion, Polynésie, etc.) avec des conditions très différentes.\n",
    "\n",
    "**Décision** : garder uniquement la métropole pour un modèle homogène.\n",
    "- On perd ~6% des données\n",
    "- Comportements routiers plus comparables\n",
    "- V2 possible avec les DOM-TOM si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1dc75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France métropolitaine : 51055 (93.8%)\n",
      "DOM-TOM ou invalides : 3347\n"
     ]
    }
   ],
   "source": [
    "# Filtrer France métropolitaine\n",
    "metropole = (\n",
    "    (df['lat'] >= 41) & (df['lat'] <= 51.5) &\n",
    "    (df['long'] >= -5.5) & (df['long'] <= 10)\n",
    ")\n",
    "print(f\"France métropolitaine : {metropole.sum()} ({metropole.mean()*100:.1f}%)\")\n",
    "print(f\"DOM-TOM ou invalides : {(~metropole).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b15417cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final : (51055, 24)\n"
     ]
    }
   ],
   "source": [
    "# Garder uniquement la France métropolitaine\n",
    "df = df[metropole].copy()\n",
    "print(f\"Dataset final : {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c18441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMA par catégorie de route (hors -1) :\n",
      "catr  agg\n",
      "1     1      90.0\n",
      "      2      70.0\n",
      "2     1      90.0\n",
      "      2      50.0\n",
      "3     1      80.0\n",
      "      2      50.0\n",
      "4     1      70.0\n",
      "      2      50.0\n",
      "5     1      50.0\n",
      "      2      30.0\n",
      "6     1      30.0\n",
      "      2      30.0\n",
      "7     1      70.0\n",
      "      2      50.0\n",
      "9     1      50.0\n",
      "      2      50.0\n",
      "Name: vma, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Voir les vma par type de route et agglomération\n",
    "print(\"VMA par catégorie de route (hors -1) :\")\n",
    "print(df[df['vma'] != -1].groupby(['catr', 'agg'])['vma'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lhujpctxyw8",
   "metadata": {},
   "source": [
    "### Imputation de vma (vitesse max autorisée)\n",
    "\n",
    "Pour les `vma == -1`, on impute la médiane basée sur :\n",
    "- `catr` : catégorie de route\n",
    "- `agg` : en agglomération ou non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f99eac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping vma :\n",
      "{(1, 1): 90.0, (1, 2): 70.0, (2, 1): 90.0, (2, 2): 50.0, (3, 1): 80.0, (3, 2): 50.0, (4, 1): 70.0, (4, 2): 50.0, (5, 1): 50.0, (5, 2): 30.0, (6, 1): 30.0, (6, 2): 30.0, (7, 1): 70.0, (7, 2): 50.0, (9, 1): 50.0, (9, 2): 50.0}\n",
      "\n",
      "VMA -1 restants : 0\n"
     ]
    }
   ],
   "source": [
    "# Créer un dictionnaire de mapping\n",
    "vma_mapping = df[df['vma'] != -1].groupby(['catr', 'agg'])['vma'].median().to_dict()\n",
    "print(\"Mapping vma :\")\n",
    "print(vma_mapping)\n",
    "\n",
    "# Imputer les -1\n",
    "def imputer_vma(row):\n",
    "    if row['vma'] == -1:\n",
    "        return vma_mapping.get((row['catr'], row['agg']), 50)  # 50 par défaut\n",
    "    return row['vma']\n",
    "\n",
    "df['vma'] = df.apply(imputer_vma, axis=1)\n",
    "\n",
    "# Vérifier\n",
    "print(f\"\\nVMA -1 restants : {(df['vma'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fl4ozdbly29",
   "metadata": {},
   "source": [
    "### Suppression de lartpc\n",
    "\n",
    "Colonne quasi-vide (28 valeurs sur 51055) - inutilisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c7c79ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lartpc - valeurs non nulles : 28\n",
      "Colonnes restantes : 23\n"
     ]
    }
   ],
   "source": [
    "# Vérifier lartpc\n",
    "print(f\"lartpc - valeurs non nulles : {df['lartpc'].notna().sum()}\")\n",
    "\n",
    "# Supprimer\n",
    "df = df.drop(columns=['lartpc'])\n",
    "print(f\"Colonnes restantes : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ow6oa5j9rc",
   "metadata": {},
   "source": [
    "### Correction de nbv\n",
    "\n",
    "La colonne `nbv` (nombre de voies) contient des valeurs `#VALEURMULTI` au lieu de nombres.\n",
    "On les remplace par la médiane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ii6lzsysiaq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques dans nbv : <StringArray>\n",
      "[           '2',            '4',            '0',            '1',\n",
      "          ' -1',            '3',            '6',            '8',\n",
      "            '5',            '9', '#VALEURMULTI',           '10',\n",
      "            '7',           '12',           '11']\n",
      "Length: 15, dtype: str...\n",
      "Type actuel : str\n",
      "\n",
      "#VALEURMULTI : 44 occurrences\n",
      "Médiane utilisée : 2.0\n",
      "Type après correction : float64\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les valeurs invalides dans nbv\n",
    "print(f\"Valeurs uniques dans nbv : {df['nbv'].unique()[:20]}...\")\n",
    "print(f\"Type actuel : {df['nbv'].dtype}\")\n",
    "\n",
    "# Compter les #VALEURMULTI\n",
    "nb_invalides = (df['nbv'] == '#VALEURMULTI').sum()\n",
    "print(f\"\\n#VALEURMULTI : {nb_invalides} occurrences\")\n",
    "\n",
    "# Corriger : remplacer par NaN puis par la médiane\n",
    "df['nbv'] = df['nbv'].replace('#VALEURMULTI', np.nan)\n",
    "df['nbv'] = df['nbv'].astype(float)\n",
    "mediane_nbv = df['nbv'].median()\n",
    "df['nbv'] = df['nbv'].fillna(mediane_nbv)\n",
    "\n",
    "print(f\"Médiane utilisée : {mediane_nbv}\")\n",
    "print(f\"Type après correction : {df['nbv'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8xsdfot1zv7",
   "metadata": {},
   "source": [
    "### Correction de larrout\n",
    "\n",
    "La colonne `larrout` (largeur de route) utilise le format français (virgule décimale).\n",
    "On convertit en float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4jjcqxpr3me",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type larrout : float64\n",
      "Exemples : [7.0, -1.0, -1.0, -1.0, 17.0]\n"
     ]
    }
   ],
   "source": [
    "# Convertir larrout : virgule → point\n",
    "df['larrout'] = df['larrout'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "print(f\"Type larrout : {df['larrout'].dtype}\")\n",
    "print(f\"Exemples : {df['larrout'].head(5).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cw5ku79g42f",
   "metadata": {},
   "source": [
    "### Features temporelles\n",
    "\n",
    "On crée des features plus exploitables à partir de la date/heure :\n",
    "- `jour_semaine` : 0 (lundi) à 6 (dimanche)\n",
    "- `is_weekend` : 1 si samedi/dimanche\n",
    "- `heure` : 0 à 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4119db45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes : 22\n",
      "   jour_semaine  is_weekend  heure\n",
      "0             0           0      7\n",
      "1             2           0     15\n",
      "2             4           0     19\n",
      "3             6           1     17\n",
      "4             0           0     19\n",
      "5             0           0      4\n",
      "6             6           1      2\n",
      "7             6           1     14\n",
      "8             6           1      3\n",
      "9             0           0     19\n"
     ]
    }
   ],
   "source": [
    "# Créer jour de la semaine (à partir de jour, mois, an)\n",
    "df['date'] = pd.to_datetime(df[['an', 'mois', 'jour']].rename(columns={'an': 'year', 'mois': 'month', 'jour': 'day'}))\n",
    "df['jour_semaine'] = df['date'].dt.dayofweek  # 0=lundi, 6=dimanche\n",
    "df['is_weekend'] = df['jour_semaine'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Extraire l'heure de hrmn (format HHMM)\n",
    "df['heure'] = df['hrmn'].astype(str).str.zfill(4).str[:2].astype(int)\n",
    "\n",
    "# Supprimer les colonnes originales devenues inutiles\n",
    "df = df.drop(columns=['jour', 'mois', 'an', 'hrmn', 'date'])\n",
    "\n",
    "print(f\"Colonnes : {df.shape[1]}\")\n",
    "print(df[['jour_semaine', 'is_weekend', 'heure']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93b014b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final : (51055, 22)\n",
      "\n",
      "Colonnes :\n",
      "['lum', 'dep', 'agg', 'int', 'atm', 'lat', 'long', 'catr', 'circ', 'nbv', 'vosp', 'prof', 'plan', 'larrout', 'surf', 'infra', 'situ', 'vma', 'mortel', 'jour_semaine', 'is_weekend', 'heure']\n",
      "\n",
      "Target (mortel) :\n",
      "mortel\n",
      "0    48044\n",
      "1     3011\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportion mortels : 5.9%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset final : {df.shape}\")\n",
    "print(f\"\\nColonnes :\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nTarget (mortel) :\")\n",
    "print(pd.Series(df['mortel']).value_counts())\n",
    "print(f\"\\nProportion mortels : {df['mortel'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pmoj8x7df7j",
   "metadata": {},
   "source": [
    "## Récap - Dataset nettoyé\n",
    "\n",
    "| Étape | Résultat |\n",
    "|-------|----------|\n",
    "| Fusion tables | 54 402 accidents |\n",
    "| Filtrage métropole | 51 055 accidents |\n",
    "| Colonnes finales | 21 features + 1 target |\n",
    "| Target | 5.9% mortels (déséquilibré) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d69a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sauvegardé : données/dataset_clean.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('../données/dataset_clean.csv', index=False)\n",
    "print(\"Dataset sauvegardé : données/dataset_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
