{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 05b - Modélisation UC2 : Étude Épidémiologique\n\n---\n\n## Objectif\n\nPrédire si un usager sera gravement blessé (target `grave_usager`) pour **identifier les facteurs de risque** et orienter la prévention.\n\n**Question UC2** : \"Quelles populations et situations cibler pour la prévention ?\"\n\n## Approche\n\n| Aspect | Choix | Justification |\n|--------|-------|---------------|\n| **Target** | `grave_usager` (17.7%) | Granularité usager, features individuelles |\n| **Ratio** | 1:4.7 | Modéré, gérable sans SMOTE |\n| **Rééquilibrage** | BalancedBagging + class_weight | Sous-échantillonnage bootstrap |\n| **Split** | Random stratifié 80/20 | Analyse rétrospective (pas de prédiction future) |\n| **Focus** | Interprétabilité | Odds ratios + feature importance |\n\n> **Différence avec UC1** : UC1 utilise un split temporel (prédiction future). UC2 utilise un split random car l'objectif est l'analyse des facteurs, pas la prédiction en production.\n\n## Pipeline\n\n1. **Baselines** : DummyClassifier + LogisticRegression\n2. **Test complet class_weight='balanced'** : 3 datasets × 5 modèles = 15 combinaisons\n3. **BalancedBagging** sur le meilleur dataset\n4. **GridSearchCV** top 3 modèles avec BalancedBagging\n5. **Facteurs de risque** : feature importance + odds ratios\n6. **Analyse des erreurs** et sauvegarde\n\n## Données\n\n| Version | Features | Fichier |\n|---------|----------|---------|\n| v1_demo | 30 | `UC2_usager_v1_demo.csv` |\n| v2_comportement | 48 | `UC2_usager_v2_comportement.csv` |\n| v3_complet | 56 | `UC2_usager_v3_complet.csv` |\n\n- **Input** : Datasets UC2 usager (04c)\n- **Output** : `model_UC2_final.joblib`, `metadata_UC2.json`\n- **Notebook précédent** : `04c_dataset_UC2_usager.ipynb`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modèles\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, recall_score, precision_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Rééchantillonnage\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Chemins\n",
    "DATA_DIR = Path(\"../../données\")\n",
    "MODELS_DIR = Path(\"../../models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "print(\"Libraries chargées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Chargement des 3 datasets usager UC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'v1_demo': pd.read_csv(DATA_DIR / 'UC2_usager_v1_demo.csv'),\n",
    "    'v2_comportement': pd.read_csv(DATA_DIR / 'UC2_usager_v2_comportement.csv'),\n",
    "    'v3_complet': pd.read_csv(DATA_DIR / 'UC2_usager_v3_complet.csv'),\n",
    "}\n",
    "\n",
    "TARGET = 'grave_usager'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASETS UC2 - ETUDE EPIDEMIOLOGIQUE (granularité usager)\")\n",
    "print(\"=\" * 60)\n",
    "for name, df in datasets.items():\n",
    "    n_features = len([c for c in df.columns if c != TARGET])\n",
    "    n_pos = df[TARGET].sum()\n",
    "    ratio = (df[TARGET] == 0).sum() / n_pos\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Features: {n_features}\")\n",
    "    print(f\"  Target grave_usager: {df[TARGET].mean():.2%} ({n_pos:,} positifs, ratio 1:{ratio:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : 477,294 usagers, dont 17.7% gravement blessés (ratio 1:4.7). Le déséquilibre est modéré comparé à UC1. Les datasets ajoutent progressivement des features (30 → 48 → 56)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_results = []\n",
    "\n",
    "for version, df in datasets.items():\n",
    "    X = df.drop(TARGET, axis=1)\n",
    "    y = df[TARGET]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Naive\n",
    "    naive = DummyClassifier(strategy='stratified', random_state=42)\n",
    "    naive.fit(X_train, y_train)\n",
    "    y_proba_n = naive.predict_proba(X_test)[:, 1]\n",
    "    y_pred_n = naive.predict(X_test)\n",
    "    baselines_results.append({\n",
    "        'dataset': version, 'model': 'Naive',\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba_n),\n",
    "        'recall': recall_score(y_test, y_pred_n),\n",
    "        'f1': f1_score(y_test, y_pred_n),\n",
    "    })\n",
    "    \n",
    "    # LogReg\n",
    "    logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_proba_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "    y_pred_lr = logreg.predict(X_test)\n",
    "    baselines_results.append({\n",
    "        'dataset': version, 'model': 'LogReg',\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba_lr),\n",
    "        'recall': recall_score(y_test, y_pred_lr),\n",
    "        'f1': f1_score(y_test, y_pred_lr),\n",
    "    })\n",
    "\n",
    "df_baselines = pd.DataFrame(baselines_results)\n",
    "print(df_baselines.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : La LogisticRegression progresse entre v1 et v2 (ajout des features démographiques et usager), mais le gain V2 → V3 est faible (ajout des features comportement/collision apporte peu de signal linéaire supplémentaire)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Test complet class_weight='balanced' : 3 datasets × 5 modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for version, df in datasets.items():\n",
    "    print(f\"\\n--- {version} ---\")\n",
    "    X = df.drop(TARGET, axis=1)\n",
    "    y = df[TARGET]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    spw = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    \n",
    "    models = {\n",
    "        'RF': RandomForestClassifier(n_estimators=100, max_depth=15, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "        'ExtraTrees': ExtraTreesClassifier(n_estimators=100, max_depth=15, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "        'XGBoost': XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, scale_pos_weight=spw, random_state=42, n_jobs=-1, verbosity=0),\n",
    "        'LightGBM': LGBMClassifier(n_estimators=100, max_depth=10, is_unbalance=True, random_state=42, n_jobs=-1, verbosity=-1),\n",
    "        'CatBoost': CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, auto_class_weights='Balanced', random_state=42, verbose=False),\n",
    "    }\n",
    "    \n",
    "    for mname, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        all_results.append({\n",
    "            'dataset': version, 'model': mname,\n",
    "            'roc_auc': auc, 'recall': rec, 'f1': f1,\n",
    "        })\n",
    "        print(f\"  {mname:12s}: ROC-AUC={auc:.3f}  Recall={rec:.3f}  F1={f1:.3f}\")\n",
    "\n",
    "df_all = pd.DataFrame(all_results)\n",
    "print(f\"\\nTotal: {len(df_all)} combinaisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau croisé ROC-AUC\n",
    "pivot_auc = df_all.pivot(index='dataset', columns='model', values='roc_auc').round(3)\n",
    "print(\"ROC-AUC :\")\n",
    "print(pivot_auc.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap Plotly\n",
    "fig = go.Figure(go.Heatmap(\n",
    "    z=pivot_auc.values, x=pivot_auc.columns.tolist(), y=pivot_auc.index.tolist(),\n",
    "    text=pivot_auc.values.round(3), texttemplate='%{text}',\n",
    "    colorscale='YlGnBu', zmin=0.5, zmax=0.85\n",
    "))\n",
    "fig.update_layout(title='UC2 — 15 combinaisons (class_weight=balanced)', height=350)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : Confirmer si le gain V2 → V3 est significatif ou quasi-nul (attendu d'après 04c). Identifier le meilleur dataset et les top 3 modèles pour la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. BalancedBagging sur le meilleur dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner le meilleur dataset\n",
    "best_dataset_row = df_all.sort_values('roc_auc', ascending=False).iloc[0]\n",
    "best_dataset_name = best_dataset_row['dataset']\n",
    "print(f\"Meilleur dataset : {best_dataset_name} ({best_dataset_row['model']} AUC={best_dataset_row['roc_auc']:.3f})\")\n",
    "\n",
    "df_best = datasets[best_dataset_name].copy()\n",
    "X = df_best.drop(TARGET, axis=1)\n",
    "y = df_best[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "spw = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}\")\n",
    "print(f\"Ratio: 1:{spw:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer class_weight seul vs BalancedBagging\n",
    "base_models = {\n",
    "    'RF': lambda: RandomForestClassifier(n_estimators=100, max_depth=15, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'ExtraTrees': lambda: ExtraTreesClassifier(n_estimators=100, max_depth=15, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'XGBoost': lambda: XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, scale_pos_weight=spw, random_state=42, n_jobs=-1, verbosity=0),\n",
    "    'LightGBM': lambda: LGBMClassifier(n_estimators=100, max_depth=10, is_unbalance=True, random_state=42, n_jobs=-1, verbosity=-1),\n",
    "    'CatBoost': lambda: CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, auto_class_weights='Balanced', random_state=42, verbose=False),\n",
    "}\n",
    "\n",
    "comparison = []\n",
    "\n",
    "for mname, model_fn in base_models.items():\n",
    "    # class_weight seul\n",
    "    m1 = model_fn()\n",
    "    m1.fit(X_train, y_train)\n",
    "    p1 = m1.predict_proba(X_test)[:, 1]\n",
    "    d1 = m1.predict(X_test)\n",
    "    \n",
    "    # BalancedBagging wrapper\n",
    "    m2_base = model_fn()\n",
    "    # Retirer le rebalancing interne pour éviter double correction\n",
    "    if hasattr(m2_base, 'class_weight'):\n",
    "        m2_base.set_params(class_weight=None)\n",
    "    if hasattr(m2_base, 'scale_pos_weight'):\n",
    "        m2_base.set_params(scale_pos_weight=1)\n",
    "    if hasattr(m2_base, 'is_unbalance'):\n",
    "        m2_base.set_params(is_unbalance=False)\n",
    "    if isinstance(m2_base, CatBoostClassifier):\n",
    "        m2_base = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, random_state=42, verbose=False)\n",
    "    \n",
    "    bb = BalancedBaggingClassifier(\n",
    "        estimator=m2_base, n_estimators=10,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    bb.fit(X_train, y_train)\n",
    "    p2 = bb.predict_proba(X_test)[:, 1]\n",
    "    d2 = bb.predict(X_test)\n",
    "    \n",
    "    comparison.append({\n",
    "        'model': mname,\n",
    "        'auc_cw': roc_auc_score(y_test, p1),\n",
    "        'recall_cw': recall_score(y_test, d1),\n",
    "        'f1_cw': f1_score(y_test, d1),\n",
    "        'auc_bb': roc_auc_score(y_test, p2),\n",
    "        'recall_bb': recall_score(y_test, d2),\n",
    "        'f1_bb': f1_score(y_test, d2),\n",
    "    })\n",
    "    print(f\"{mname:12s}: CW AUC={comparison[-1]['auc_cw']:.3f} F1={comparison[-1]['f1_cw']:.3f}  |  BB AUC={comparison[-1]['auc_bb']:.3f} F1={comparison[-1]['f1_bb']:.3f}\")\n",
    "\n",
    "df_comp = pd.DataFrame(comparison)\n",
    "df_comp['delta_auc'] = df_comp['auc_bb'] - df_comp['auc_cw']\n",
    "df_comp['delta_f1'] = df_comp['f1_bb'] - df_comp['f1_cw']\n",
    "print(\"\\n\" + df_comp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot comparatif\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(name='ROC-AUC (class_weight)', x=df_comp['model'], y=df_comp['auc_cw'], marker_color='#3498db', opacity=0.7))\n",
    "fig.add_trace(go.Bar(name='ROC-AUC (BalancedBagging)', x=df_comp['model'], y=df_comp['auc_bb'], marker_color='#2ecc71', opacity=0.7))\n",
    "fig.add_trace(go.Bar(name='F1 (class_weight)', x=df_comp['model'], y=df_comp['f1_cw'], marker_color='#e74c3c', opacity=0.5))\n",
    "fig.add_trace(go.Bar(name='F1 (BalancedBagging)', x=df_comp['model'], y=df_comp['f1_bb'], marker_color='#f39c12', opacity=0.5))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'class_weight vs BalancedBagging ({best_dataset_name})',\n",
    "    barmode='group', yaxis_range=[0, 1], height=450\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : BalancedBagging améliore (ou maintient) le ROC-AUC et le F1 sur la plupart des modèles. Le gain est surtout visible sur le Recall, important pour ne pas sous-estimer les cas graves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. GridSearchCV top 3 modèles (avec BalancedBagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les top 3 par ROC-AUC (BalancedBagging)\n",
    "top3 = df_comp.nlargest(3, 'auc_bb')['model'].tolist()\n",
    "print(f\"Top 3 modèles pour GridSearch : {top3}\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Grilles étroites adaptées aux modèles identifiés\n",
    "grid_defs = {\n",
    "    'LightGBM': {\n",
    "        'base': LGBMClassifier(random_state=42, n_jobs=1, verbosity=-1),\n",
    "        'params': {\n",
    "            'estimator__n_estimators': [200, 300],\n",
    "            'estimator__max_depth': [10, 15, -1],\n",
    "            'estimator__learning_rate': [0.05, 0.1],\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'base': XGBClassifier(random_state=42, n_jobs=1, verbosity=0),\n",
    "        'params': {\n",
    "            'estimator__n_estimators': [200, 300],\n",
    "            'estimator__max_depth': [4, 6],\n",
    "            'estimator__learning_rate': [0.05, 0.1],\n",
    "        }\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'base': CatBoostClassifier(random_state=42, verbose=False),\n",
    "        'params': {\n",
    "            'estimator__iterations': [200, 300],\n",
    "            'estimator__depth': [4, 6],\n",
    "            'estimator__learning_rate': [0.05, 0.1],\n",
    "        }\n",
    "    },\n",
    "    'RF': {\n",
    "        'base': RandomForestClassifier(random_state=42, n_jobs=1),\n",
    "        'params': {\n",
    "            'estimator__n_estimators': [100, 200],\n",
    "            'estimator__max_depth': [10, 15, 20],\n",
    "            'estimator__min_samples_leaf': [1, 2],\n",
    "        }\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'base': ExtraTreesClassifier(random_state=42, n_jobs=1),\n",
    "        'params': {\n",
    "            'estimator__n_estimators': [100, 200],\n",
    "            'estimator__max_depth': [10, 15, 20],\n",
    "            'estimator__min_samples_leaf': [1, 2],\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "grid_results = []\n",
    "grid_models = {}\n",
    "grid_probas = {}\n",
    "\n",
    "for mname in top3:\n",
    "    print(f\"\\n--- GridSearch {mname} (BalancedBagging) ---\")\n",
    "    cfg = grid_defs[mname]\n",
    "    \n",
    "    bb = BalancedBaggingClassifier(\n",
    "        estimator=cfg['base'], n_estimators=10,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        bb, cfg['params'],\n",
    "        cv=cv, scoring='roc_auc', n_jobs=-1, verbose=0\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    best = gs.best_estimator_\n",
    "    y_proba = best.predict_proba(X_test)[:, 1]\n",
    "    y_pred = best.predict(X_test)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    grid_results.append({\n",
    "        'model': mname, 'roc_auc': auc, 'recall': rec,\n",
    "        'precision': prec, 'f1': f1,\n",
    "        'best_params': str(gs.best_params_)\n",
    "    })\n",
    "    grid_models[mname] = best\n",
    "    grid_probas[mname] = y_proba\n",
    "    \n",
    "    print(f\"  Best params: {gs.best_params_}\")\n",
    "    print(f\"  ROC-AUC={auc:.3f}  Recall={rec:.3f}  F1={f1:.3f}\")\n",
    "\n",
    "df_grid = pd.DataFrame(grid_results)\n",
    "print(\"\\n\" + df_grid[['model', 'roc_auc', 'recall', 'precision', 'f1']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : Le GridSearch avec BalancedBagging optimise les hyperparamtres. Comparer avec la section 3 (class_weight seul, params par défaut) pour quantifier le gain cumulé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Facteurs de risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner le meilleur modèle\n",
    "best_idx = df_grid['roc_auc'].idxmax()\n",
    "best_model_name = df_grid.loc[best_idx, 'model']\n",
    "best_model = grid_models[best_model_name]\n",
    "y_proba_best = grid_probas[best_model_name]\n",
    "\n",
    "print(f\"Modèle sélectionné : {best_model_name}\")\n",
    "print(f\"ROC-AUC={df_grid.loc[best_idx, 'roc_auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (moyenne sur les estimateurs du BalancedBagging)\n",
    "importances_list = []\n",
    "for est in best_model.estimators_:\n",
    "    if hasattr(est, 'feature_importances_'):\n",
    "        importances_list.append(est.feature_importances_)\n",
    "\n",
    "if importances_list:\n",
    "    importances = np.mean(importances_list, axis=0)\n",
    "    fi_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=True).tail(15)\n",
    "    \n",
    "    fig = px.bar(\n",
    "        fi_df, x='importance', y='feature', orientation='h',\n",
    "        title=f'Top 15 Feature Importance — {best_model_name} (BalancedBagging)',\n",
    "        color='importance', color_continuous_scale='Blues'\n",
    "    )\n",
    "    fig.update_layout(height=500, showlegend=False)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\nTop 15 :\")\n",
    "    print(fi_df.sort_values('importance', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds ratios / risk ratios pour features binaires\n",
    "print(\"=\" * 60)\n",
    "print(\"FACTEURS DE RISQUE (Odds Ratios)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "risk_data = []\n",
    "for col in X.columns:\n",
    "    if df_best[col].nunique() == 2:  # Feature binaire\n",
    "        n1 = (df_best[col] == 1).sum()\n",
    "        if n1 < 100:\n",
    "            continue\n",
    "        # Taux de gravité avec/sans la feature\n",
    "        rate_1 = df_best[df_best[col] == 1][TARGET].mean()\n",
    "        rate_0 = df_best[df_best[col] == 0][TARGET].mean()\n",
    "        \n",
    "        # Odds ratio\n",
    "        odds_1 = rate_1 / (1 - rate_1) if rate_1 < 1 else float('inf')\n",
    "        odds_0 = rate_0 / (1 - rate_0) if rate_0 < 1 else float('inf')\n",
    "        odds_ratio = odds_1 / odds_0 if odds_0 > 0 else float('inf')\n",
    "        \n",
    "        risk_data.append({\n",
    "            'feature': col,\n",
    "            'taux_grave (=1)': rate_1,\n",
    "            'taux_grave (=0)': rate_0,\n",
    "            'odds_ratio': odds_ratio,\n",
    "            'n_exposes': n1,\n",
    "        })\n",
    "\n",
    "df_risk = pd.DataFrame(risk_data).sort_values('odds_ratio', ascending=False)\n",
    "print(\"\\nTop 10 facteurs aggravants (OR > 1) :\")\n",
    "print(df_risk.head(10).round(3).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 facteurs protecteurs (OR < 1) :\")\n",
    "print(df_risk.tail(5).round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des odds ratios\n",
    "df_risk_top = pd.concat([df_risk.head(10), df_risk.tail(5)])\n",
    "df_risk_top = df_risk_top.sort_values('odds_ratio')\n",
    "\n",
    "colors = ['#e74c3c' if x > 1 else '#2ecc71' for x in df_risk_top['odds_ratio']]\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=df_risk_top['odds_ratio'],\n",
    "    y=df_risk_top['feature'],\n",
    "    orientation='h',\n",
    "    marker_color=colors,\n",
    "))\n",
    "fig.add_vline(x=1, line_dash='dash', line_color='black')\n",
    "fig.update_layout(\n",
    "    title='Odds Ratios — Facteurs de risque de blessure grave',\n",
    "    xaxis_title='Odds Ratio (>1 = aggravant, <1 = protecteur)',\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : Les facteurs de risque identifiés sont cohérents avec l'épidémiologie de la sécurité routière : absence de ceinture, piétons, personnes âgées (65+), usagers vulnérables, accidents hors agglomération, obstacles fixes. Les facteurs protecteurs incluent le port du casque et les trajets domicile-travail (réguliers, prudence accrue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Analyse des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "labels = ['Non grave', 'Grave']\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm, text_auto=True, x=labels, y=labels,\n",
    "    color_continuous_scale='Blues',\n",
    "    labels=dict(x='Prédit', y='Réel', color='Nombre')\n",
    ")\n",
    "fig.update_layout(title=f'Matrice de confusion — {best_model_name} (BalancedBagging)', height=400)\n",
    "fig.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred_best, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des scores par classe\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=y_proba_best[y_test == 0], name='Non grave',\n",
    "    marker_color='#3498db', opacity=0.6, nbinsx=50\n",
    "))\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=y_proba_best[y_test == 1], name='Grave',\n",
    "    marker_color='#e74c3c', opacity=0.6, nbinsx=50\n",
    "))\n",
    "fig.add_vline(x=0.5, line_dash='dash', line_color='black', annotation_text='Seuil 0.5')\n",
    "fig.update_layout(\n",
    "    title='Distribution des scores de risque par classe',\n",
    "    xaxis_title='Score de risque', yaxis_title='Nombre d\\'usagers',\n",
    "    barmode='overlay', height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : La séparation des distributions montre la capacité discriminante du modèle. Un bon modèle sépare bien les deux distributions. Analyser le recouvrement pour comprendre les cas difficiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Sauvegarde du modèle final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réentraîner sur toutes les données\n",
    "print(\"Réentraînement sur l'ensemble des données...\")\n",
    "\n",
    "X_full = df_best.drop(TARGET, axis=1)\n",
    "y_full = df_best[TARGET]\n",
    "\n",
    "# Recréer le BalancedBagging avec les meilleurs params\n",
    "final_model = grid_models[best_model_name].__class__(\n",
    "    **grid_models[best_model_name].get_params()\n",
    ")\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "print(f\"Modèle {best_model_name} (BalancedBagging) réentraîné sur {X_full.shape[0]:,} usagers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder\n",
    "model_path = MODELS_DIR / 'model_UC2_final.joblib'\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"Modèle sauvegardé : {model_path}\")\n",
    "\n",
    "# Métadonnées\n",
    "best_metrics = df_grid.loc[best_idx]\n",
    "metadata = {\n",
    "    'features': list(X_full.columns),\n",
    "    'target': TARGET,\n",
    "    'model_type': f'BalancedBagging({best_model_name})',\n",
    "    'best_params': best_metrics['best_params'],\n",
    "    'resampling': 'BalancedBaggingClassifier(n_estimators=10)',\n",
    "    'metrics': {\n",
    "        'roc_auc': float(best_metrics['roc_auc']),\n",
    "        'recall': float(best_metrics['recall']),\n",
    "        'precision': float(best_metrics['precision']),\n",
    "        'f1': float(best_metrics['f1']),\n",
    "    },\n",
    "}\n",
    "\n",
    "meta_path = MODELS_DIR / 'metadata_UC2.json'\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "print(f\"Métadonnées sauvegardées : {meta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Résumé + Recommandations prévention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUME FINAL — UC2 ETUDE EPIDEMIOLOGIQUE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Baselines\n",
    "bl_best = df_baselines[df_baselines['dataset'] == best_dataset_name]\n",
    "bl_naive = bl_best[bl_best['model'] == 'Naive']['roc_auc'].values[0]\n",
    "bl_lr = bl_best[bl_best['model'] == 'LogReg']['roc_auc'].values[0]\n",
    "\n",
    "# Sans BalancedBagging\n",
    "sans_bb = df_all[df_all['dataset'] == best_dataset_name].sort_values('roc_auc', ascending=False).iloc[0]\n",
    "\n",
    "# Avec BalancedBagging + GridSearch\n",
    "best_final = df_grid.loc[best_idx]\n",
    "\n",
    "recap = pd.DataFrame([\n",
    "    {'Etape': 'Naive', 'ROC-AUC': bl_naive, 'F1': '-', 'Méthode': 'DummyClassifier'},\n",
    "    {'Etape': 'LogReg (balanced)', 'ROC-AUC': bl_lr, 'F1': bl_best[bl_best['model']=='LogReg']['f1'].values[0], 'Méthode': 'LogisticRegression'},\n",
    "    {'Etape': 'Meilleur sans BB', 'ROC-AUC': sans_bb['roc_auc'], 'F1': sans_bb['f1'], 'Méthode': f\"{sans_bb['model']} (class_weight)\"},\n",
    "    {'Etape': 'BB + GridSearch', 'ROC-AUC': best_final['roc_auc'], 'F1': best_final['f1'], 'Méthode': f\"BalancedBagging({best_model_name})\"},\n",
    "])\n",
    "print(\"\\n\" + recap.to_string(index=False))\n",
    "\n",
    "print(f\"\\nMODELE FINAL : BalancedBagging({best_model_name})\")\n",
    "print(f\"Fichiers :\")\n",
    "print(f\"  {model_path}\")\n",
    "print(f\"  {meta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandations prévention\n",
    "\n",
    "Basé sur l'analyse des facteurs de risque :\n",
    "\n",
    "**Populations prioritaires :**\n",
    "1. **Usagers sans ceinture** — odds ratio élevé, facteur évitable\n",
    "2. **Piétons** — vulnérabilité intrinsèque, aménagements urbains\n",
    "3. **Personnes âgées (65+)** — fragilité physique, adaptation des véhicules\n",
    "4. **Cyclistes et EDPs** — équipements de protection, pistes dédiées\n",
    "5. **Accidents hors agglomération** — vitesse, éloignement des secours\n",
    "\n",
    "**Facteurs protecteurs à renforcer :**\n",
    "- Port du casque (deux-roues)\n",
    "- Port de la ceinture (véhicules)\n",
    "- Aménagements piétons sécurisés\n",
    "\n",
    "Ces résultats peuvent orienter les campagnes de prévention et les politiques de sécurité routière."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}