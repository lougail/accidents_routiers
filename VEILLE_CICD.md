# üìö Phase 0 : Veille Technologique

---

## üìù Missions de veille


### Mission 1 : Comprendre CI/CD

---

### 1. Qu'est-ce que la Continuous Integration ?

**Quels probl√®mes r√©sout-elle ?**

La CI permet d'int√©grer en continu le travail des diff√©rents collaborateurs sur un repo. √Ä chaque commit / push, le code est test√© avant d'√™tre merg√© automatiquement.

Cela √©vite le **"integration hell"** : chacun code dans son coin pendant de longues p√©riodes, et le jour o√π il faut tout merge pour mettre en prod, c'est le calvaire. La CI permet de faire des int√©grations au fur et √† mesure ; ainsi, quand une nouvelle int√©gration casse le code, on sait directement quelle partie est probl√©matique.

Par ailleurs, cela permet de tester le code dans un environnement standardis√© √† chaque push, ce qui r√©sout le probl√®me du *"√ßa marche sur ma machine mais pas celle des autres"*.

**Quels sont les principes cl√©s ?**

- Maintenir un **repo unique** avec un syst√®me de versioning.
- Chaque commit d√©clenche un **workflow automatique** qui build et ex√©cute les tests. Les v√©rifications ne doivent pas √™tre manuelles.
- D√®s qu'un build casse, la **priorit√©** devient de r√©parer le probl√®me avant de continuer tout autre d√©veloppement.

**3 exemples d'outils de CI :**

- GitHub Actions
- GitLab CI/CD
- Jenkins

---

### 2. Qu'est-ce que le Continuous Deployment / Delivery ?

**Diff√©rence entre Continuous Delivery et Continuous Deployment**

- **Continuous Delivery :** on automatise toute la pipeline jusqu'au d√©ploiement sur l'environnement de staging, mais la derni√®re √©tape de mise en production doit toujours √™tre valid√©e et approuv√©e par un membre de l'√©quipe.
- **Continuous Deployment :** on automatise toute la pipeline CI/CD jusqu'au d√©ploiement sur l'environnement de production. Tout est automatis√©, du commit du dev √† la mise en production de l'appli.

> Pour r√©sumer ‚Äî Delivery = *"on peut d√©ployer √† tout moment"* | Deployment = *"on d√©ploie en continu"*

**Risques**

- **D√©ployer un bug en production :** le d√©ploiement √©tant automatis√©, il faut √™tre certain d'avoir des tests solides avec une bonne couverture de code, sinon on automatise la livraison de bugs.
- **Complexit√© de mise en place :** il faut investir du temps et des ressources pour mettre en place tout le syst√®me (pipelines, environnements de staging, monitoring, rollback‚Ä¶).
- **Contexte inadapt√© :** dans certains domaines (banques, sant√©‚Ä¶), la validation humaine reste imp√©rative (conformit√© l√©gale, approbation m√©tier‚Ä¶). Dans ce cas, le Continuous Delivery est plus adapt√©.

**B√©n√©fices**

- **Rapidit√© de mise en production :** les utilisateurs profitent plus vite des nouvelles fonctionnalit√©s et des corrections, et les d√©veloppeurs obtiennent des feedbacks rapides.
- **D√©ploiements atomiques :** chaque d√©ploiement contient peu de changements, ce qui permet d'identifier facilement ce qui a cass√© l'application.
- **R√©duction du travail r√©p√©titif :** les devs n'ont plus √† g√©rer manuellement la mise en production.

---

### 3. Pourquoi CI/CD est important ?

**Impact sur la qualit√© du code**

Tout le code est test√© √† chaque commit (tests unitaires, tests d'int√©gration, linting, v√©rification de la couverture du code). Rien n'arrive en production sans avoir subi tous ces tests. Cela s√©curise la mise en production : si un d√©veloppeur introduit une r√©gression ou un bug, il est d√©tect√© imm√©diatement et non pas trois semaines plus tard lors de l'ex√©cution manuelle des tests. On sait aussi pr√©cis√©ment quelle partie du code a cr√©√© le probl√®me.

Par ailleurs, cela incite l'√©quipe √† avoir des tests complets et √† jour. Les tests deviennent une n√©cessit√© concr√®te, car un code mal test√© peut bloquer tout le pipeline.

**Impact sur la vitesse de d√©veloppement**

Sans CI/CD, une fois qu'il a fini son code, le dev doit lancer les tests √† la main, pr√©parer le build, copier les fichiers vers le serveur, v√©rifier que tout tourne en prod‚Ä¶ Le but du CI/CD est d'automatiser tout √ßa : le dev commit et push son code, la pipeline s'ex√©cute, et si tout est OK le code est d√©ploy√© automatiquement en production. Le dev peut imm√©diatement passer √† sa t√¢che suivante, sans avoir √† g√©rer les tests et la mise en prod.

**Impact sur la collaboration en √©quipe**

Le CI/CD √©vite que des devs se retrouvent isol√©s sur des sujets s√©par√©s et que les projets divergent. On push et merge au fur et √† mesure, ce qui assure que toutes les personnes qui travaillent sur le projet ont le code √† jour en permanence et que ce qu'ils d√©veloppent s'int√®gre facilement √† ce qui est d√©j√† en place.

Cela permet aussi d'avoir un **standard commun et objectif** pour la validation du code. Ce n'est plus subjectif ou conditionn√© par ton statut dans la bo√Æte : tout le code passe par la pipeline, c'est elle qui a valeur de v√©rit√©. Soit elle valide ton code, soit √ßa casse et toute l'√©quipe doit corriger ensemble le probl√®me. Cela favorise la culture de la responsabilit√© partag√©e.

---

### Mission 2 : Ma√Ætriser uv

---

### 1. Qu'est-ce que uv ?

**En quoi est-ce diff√©rent de pip/poetry/pipenv ?**

- **pip** est juste un installateur de paquets. Il ne g√®re ni les environnements virtuels, ni les lockfiles, ni la r√©solution intelligente des conflits de versions. C'est l'outil de base, mais il faut le combiner avec d'autres outils (venv, pip-tools...) pour avoir un workflow complet.

- **pipenv** a √©t√© la premi√®re tentative d'unifier pip + virtualenv + lockfile dans un seul outil. Il introduit le Pipfile.lock pour des installations reproductibles. Mais il est lent, et son d√©veloppement a stagn√©.

- **poetry** est devenu le standard de facto : il g√®re tout (d√©pendances, environnements, build, publication sur PyPI) avec une bonne UX. Son d√©faut : il utilise son propre format (pyproject.toml avec des sections [tool.poetry]) et peut √™tre lent sur les gros projets.

- **uv** est d√©velopp√© par Astral (les cr√©ateurs de Ruff) et r√©√©crit tout en Rust. Il remplace pip, venv, pip-tools et m√™me pyenv dans un seul binaire ultra-rapide. Contrairement √† poetry, il utilise les standards Python (PEP 621) sans sections propri√©taires.

> Pour r√©sumer ‚Äî pip = installateur basique | pipenv = tentative d'unification (abandonn√©e) | poetry = solution compl√®te mais lente | uv = tout-en-un rapide et standard

**Quels sont les avantages ?**

- **Vitesse** : √©crit en Rust avec une r√©solution des d√©pendances parall√©lis√©e, uv est 10 √† 100 fois plus rapide que pip ou poetry. Sur un gros projet, uv sync prend quelques secondes l√† o√π poetry install peut prendre plusieurs minutes.

- **Tout-en-un** : uv peut installer Python lui-m√™me (uv python install 3.12), cr√©er des environnements virtuels, installer les d√©pendances et ex√©cuter des commandes. Plus besoin de jongler entre pyenv, venv et pip.

- **Standards Python** : uv utilise pyproject.toml au format PEP 621, le standard officiel. Pas de format propri√©taire, donc facile √† migrer vers ou depuis un autre outil.

- **Reproductibilit√©** : le fichier uv.lock garantit que tous les d√©veloppeurs et la CI installent exactement les m√™mes versions, √† l'octet pr√®s.

- **Drop-in replacement** : uv pip install requests fonctionne exactement comme pip install requests. On peut migrer progressivement sans tout casser.

---

### 2. Comment uv fonctionne avec pyproject.toml ?

**Structure du fichier**

Le pyproject.toml est le fichier de configuration standard pour les projets Python (PEP 621). Il contient trois sections principales :

- [project] : les m√©tadonn√©es du projet (nom, version, description, version Python requise, d√©pendances)
- [project.optional-dependencies] : les d√©pendances optionnelles group√©es par usage (dev, test, docs...)
- [build-system] : le backend utilis√© pour construire le package

**Gestion des d√©pendances (s√©par√© par sections)**

```toml
[project]
name = "mon-projet"
version = "0.1.0"
requires-python = ">=3.10"

# D√©pendances de production (install√©es par d√©faut)
dependencies = [
    "fastapi>=0.100.0",
    "pandas>=2.0.0",
]

[project.optional-dependencies]
# D√©pendances de dev : uv sync --extra dev
dev = [
    "pytest>=7.0.0",
    "ruff>=0.1.0",
]
# D√©pendances de docs : uv sync --extra docs
docs = [
    "mkdocs>=1.5.0",
]
```

Pour installer les d√©pendances de prod + dev : uv sync --extra dev

**Build backend**

Le build backend est l'outil qui transforme ton code source en package installable (.whl, .tar.gz). Les plus courants :

- **hatchling** : moderne, rapide, recommand√© par d√©faut
- **setuptools** : l'historique, encore tr√®s utilis√©
- **flit-core** : minimaliste, pour les packages simples

```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

---

### 3. Comment utiliser uv dans GitHub Actions ?

**Installation**

Astral fournit une action officielle astral-sh/setup-uv qui installe uv dans le runner :

```yaml
- name: Install uv
  uses: astral-sh/setup-uv@v3
```

Pas besoin d'installer Python s√©par√©ment : uv peut le faire lui-m√™me si n√©cessaire.

**Cache des d√©pendances**

Pour √©viter de re-t√©l√©charger les d√©pendances √† chaque run, on met en cache le dossier ~/.cache/uv. La cl√© du cache est bas√©e sur le hash du lockfile : si les d√©pendances changent, le cache est invalid√©.

```yaml
- name: Cache uv dependencies
  uses: actions/cache@v4
  with:
    path: ~/.cache/uv
    key: ${{ runner.os }}-uv-${{ hashFiles('uv.lock') }}
```

**Ex√©cution de commandes**

```yaml
- name: Install dependencies
  run: uv sync --frozen

- name: Run tests
  run: uv run pytest

- name: Run linter
  run: uv run ruff check .
```

- uv sync --frozen : installe les d√©pendances exactes du lockfile sans le mettre √† jour (important en CI pour la reproductibilit√©)
- uv run <cmd> : ex√©cute une commande dans l'environnement virtuel sans avoir besoin de l'activer manuellement

---

### Mission 3 : Comprendre Semantic Release

---

### 1. Qu'est-ce que le versionnage s√©mantique (SemVer) ?

**Format MAJOR.MINOR.PATCH**

Le versionnage s√©mantique (ou SemVer) est une convention pour num√©roter les versions d'un logiciel de mani√®re coh√©rente et compr√©hensible. Le format est X.Y.Z :

- **X (MAJOR)** : la version majeure. Elle change quand on introduit des modifications incompatibles avec les versions pr√©c√©dentes.
- **Y (MINOR)** : la version mineure. Elle change quand on ajoute des fonctionnalit√©s tout en restant r√©trocompatible.
- **Z (PATCH)** : le correctif. Il change quand on corrige des bugs sans modifier l'API.

Par exemple, 2.4.1 signifie : deuxi√®me version majeure, quatri√®me ajout de fonctionnalit√©s depuis la v2, premier correctif depuis la v2.4.

**Quand bumper chaque niveau ?**

- On **bump le PATCH** (1.0.0 ‚Üí 1.0.1) quand on corrige un bug sans changer le comportement de l'API. Les utilisateurs peuvent mettre √† jour sans rien modifier dans leur code.

- On **bump le MINOR** (1.0.0 ‚Üí 1.1.0) quand on ajoute une nouvelle fonctionnalit√© qui n'impacte pas le code existant. Le code des utilisateurs reste compatible.

- On **bump le MAJOR** (1.0.0 ‚Üí 2.0.0) quand on fait un changement qui casse la compatibilit√© : renommage de fonction, suppression d'un param√®tre, changement de comportement par d√©faut... Les utilisateurs devront potentiellement adapter leur code.

> R√®gle importante : quand on bump un niveau, on remet les niveaux inf√©rieurs √† z√©ro. Exemple : 1.4.3 ‚Üí 2.0.0 (et non 2.4.3).

---

### 2. Qu'est-ce que Conventional Commits ?

**Format des messages**

Conventional Commits est une convention pour structurer les messages de commit de mani√®re standardis√©e. Le format est :

```
<type>(<scope>): <description>

[corps optionnel]

[footer optionnel]
```

Exemples :
- feat(auth): add login with Google
- fix(api): handle null response from server
- docs: update README with installation steps

Le scope (entre parenth√®ses) est optionnel et indique la partie du ode concern√©e.

**Types de commits (feat, fix, etc.)**

- **feat** : nouvelle fonctionnalit√©
- **fix** : correction de bug
- **docs** : modification de la documentation uniquement
- **style** : formatage, point-virgules manquants... (pas de changement de logique)
- **refactor** : refactorisation du code (ni feature, ni fix)
- **test** : ajout ou modification de tests
- **chore** : maintenance, mise √† jour de d√©pendances, config...

**Impact sur le versionnage**

C'est l√† que Conventional Commits devient puissant : le type de commit d√©termine automatiquement quel niveau de version bumper.

- fix: ‚Üí bump **PATCH** (1.0.0 ‚Üí 1.0.1)
- feat: ‚Üí bump **MINOR** (1.0.0 ‚Üí 1.1.0)
- feat!: ou BREAKING CHANGE: dans le footer ‚Üí bump **MAJOR** (1.0.0 ‚Üí 2.0.0)

Les autres types (docs, style, refactor, test, chore) ne d√©clenchent pas de nouvelle version par d√©faut.

> L'int√©r√™t : on peut automatiser enti√®rement le versionnage. Un outil comme python-semantic-release lit l'historique des commits, d√©termine le bon niveau de version et cr√©e la release automatiquement.

---

### 3. Comment python-semantic-release fonctionne ?

**Configuration dans pyproject.toml**

python-semantic-release se configure dans le pyproject.toml avec la section [tool.semantic_release] :

```toml
[tool.semantic_release]
version_variable = "src/__init__.py:__version__"
version_toml = ["pyproject.toml:project.version"]
branch = "main"
upload_to_pypi = false
upload_to_release = true
build_command = "uv build"
```

- version_variable : o√π mettre √† jour la version dans le code
- version_toml : o√π mettre √† jour la version dans pyproject.toml
- branch : la branche sur laquelle d√©clencher les releases
- upload_to_release : cr√©er une release GitHub avec les assets

**G√©n√©ration du CHANGELOG**

python-semantic-release g√©n√®re automatiquement un CHANGELOG.md √† partir des commits. Il regroupe les commits par type et par version :

```markdown
## v1.2.0 (2024-01-15)

### Features
- Add user authentication (feat(auth): add login endpoint)

### Bug Fixes
- Fix crash on empty input (fix(parser): handle null values)
```

Le changelog est mis √† jour √† chaque release, ce qui documente automatiquement l'√©volution du projet.

**Cr√©ation des releases GitHub**

Quand python-semantic-release s'ex√©cute (g√©n√©ralement dans une GitHub Action), il :

1. Analyse les commits depuis la derni√®re release
2. D√©termine le nouveau num√©ro de version selon les types de commits
3. Met √† jour les fichiers de version (pyproject.toml, __init__.py...)
4. Met √† jour le CHANGELOG
5. Cr√©e un commit et un tag Git
6. Cr√©e une release GitHub avec les notes de version

Le tout automatiquement, sans intervention humaine.

---

### Mission 5 : MkDocs & GitHub Pages (bonus)

---

### 1. Comment MkDocs g√©n√®re de la documentation ?

MkDocs est un g√©n√©rateur de sites statiques con√ßu sp√©cifiquement pour la documentation. Tu √©cris tes docs en Markdown, et MkDocs les transforme en un site web navigable.

**Structure d'un projet MkDocs :**

```
mon-projet/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ index.md          # Page d'accueil
‚îÇ   ‚îú‚îÄ‚îÄ installation.md   # Autres pages
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îî‚îÄ‚îÄ reference.md
‚îú‚îÄ‚îÄ mkdocs.yml            # Configuration
‚îî‚îÄ‚îÄ src/                  # Ton code Python
```

**Configuration minimale (mkdocs.yml) :**

```yaml
site_name: Mon Projet
theme:
  name: material    # Theme Material (le plus populaire)
nav:
  - Accueil: index.md
  - Installation: installation.md
  - API: api/reference.md
```

**Commandes principales :**

- mkdocs serve : lance un serveur local avec hot-reload
- mkdocs build : g√©n√®re le site statique dans site/

---

### 2. Comment d√©ployer sur GitHub Pages ?

GitHub Pages h√©berge gratuitement des sites statiques. Deux options :

**Option 1 : Commande manuelle**

```bash
mkdocs gh-deploy
```

Cette commande build le site et le push sur la branche gh-pages automatiquement.

**Option 2 : GitHub Actions (recommand√©)**

```yaml
name: Deploy docs
on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v3
      - run: uv sync --extra docs
      - run: uv run mkdocs gh-deploy --force
```

Le site sera accessible √† https://<username>.github.io/<repo>/

---

### 3. Qu'est-ce que mkdocstrings ?

mkdocstrings est un plugin MkDocs qui g√©n√®re automatiquement la documentation de ton API √† partir des docstrings de ton code Python.

Au lieu d'√©crire manuellement la doc de chaque fonction, tu √©cris dans ton Markdown :

```markdown
# API Reference

::: mon_module.ma_fonction
```

Et mkdocstrings va chercher la fonction dans ton code, lire sa docstring, ses param√®tres, ses types, et g√©n√©rer une belle page de documentation.

**Configuration :**

```yaml
plugins:
  - mkdocstrings:
      handlers:
        python:
          options:
            show_source: true
            show_signature_annotations: true
```

**Exemple de docstring qui sera pars√©e :**

```python
def calculate_sum(a: int, b: int) -> int:
    """Calcule la somme de deux nombres.

    Args:
        a: Premier nombre
        b: Deuxi√®me nombre

    Returns:
        La somme de a et b
    """
    return a + b
```

> L'int√©r√™t : ta doc API est toujours √† jour car elle est g√©n√©r√©e directement depuis le code. Plus de doc obsol√®te qui ne correspond plus au code.

